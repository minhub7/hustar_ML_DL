{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3583f622-431c-4c32-a100-5732a90d9a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import Model, layers\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7805926e-b65d-4d16-9dc6-e1286c86dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(Model):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.encoder = Sequential([\n",
    "                                   layers.Dense(20, activation='relu'), # Fully connected layer\n",
    "                                   layers.Dense(30, activation='relu'),\n",
    "                                   layers.Dense(10),\n",
    "        ])\n",
    "        \n",
    "#     def call(self, x):\n",
    "#         mu, logvar = tf.split(self.encoder(x), 2, axis=1)\n",
    "        \n",
    "#         return mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7746574f-28e5-4b76-9f20-5a2400313dc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23466/3063861750.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested)\u001b[0m\n\u001b[1;32m   2577\u001b[0m     \"\"\"\n\u001b[1;32m   2578\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2579\u001b[0;31m       raise ValueError(\n\u001b[0m\u001b[1;32m   2580\u001b[0m           \u001b[0;34m'This model has not yet been built. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2581\u001b[0m           \u001b[0;34m'Build the model first by calling `build()` or by calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "model = NeuralNet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef7f2e01-f382-4a99-ae45-295fbc5f17ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = Sequential([layers.Flatten(), # 1차원 Vector로 만듬\n",
    "                                   layers.Dense(512, activation='relu'), # Fully connected layer\n",
    "                                   layers.Dense(256, activation='relu'),\n",
    "                                   layers.Dense(latent_dim * 2),\n",
    "        ])\n",
    "        \n",
    "    def call(self, x):\n",
    "        mu, logvar = tf.split(self.encoder(x), 2, axis=1)\n",
    "        \n",
    "        return mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9237982-51b5-4769-abdf-c95dd7a34bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.decoder = Sequential([layers.Input([2, 1])\n",
    "                                   layers.Dense(256, activation='relu'),\n",
    "                                   layers.Dense(512, activation='relu'),\n",
    "                                   layers.Dense(784, activation='sigmoid'),\n",
    "                                   layers.Reshape((28, 28, 1))\n",
    "                                  ])\n",
    "       \n",
    "    def call(self, z):\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71c75c84-d395-4778-81e3-2dd4cfbe6020",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "latent_dim = 2\n",
    "learning_rate = 1e-3\n",
    "log_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f7233e0-6502-4ec4-8a3e-160b789ca2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(latent_dim)\n",
    "decoder = Decoder(latent_dim)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b4e7bcd-b90d-4911-8965-d21c0c06dabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(mu, logvar):\n",
    "    sample_ = tf.random.normal(mu.shape) # z~N(0,1) => z~(mu, var) ~ mu + sigma * z\n",
    "    sigma = tf.exp(0.5*logvar)  # exp(0.5 log sigma^(2)) => sigma\n",
    "    return mu + sample_ * sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7997256e-e7dd-4e08-a4df-71ee1a79741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inputs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        mu, logvar = encoder(inputs)\n",
    "        z = sample(mu, logvar)\n",
    "        x_recon = decoder(z)\n",
    "        \n",
    "        \n",
    "        # loss\n",
    "        reconstruction_error = tf.reduce_sum(tf.loss.binary_crossentorpy(inputs, x_recon))\n",
    "        kl = 0.5 * tf.reduce_sum(tf.exp(logvar) + tf.square(mu)-1.-logvar)\n",
    "        loss = (kl + reconstruction_error)/inputs.shape[0]\n",
    "        \n",
    "    vars_ = encoder.trainable_variables + decoder.trainable_variables\n",
    "    grads_ = tape.gradient(loss, vars_)\n",
    "    optimizer.apply_gradients(zip(grads_, vars_))\n",
    "    \n",
    "    return loo, reconstruction_error, kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bacdc8-7abb-4634-b8f2-600fd68f785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tfds.load('mnist', split='train')\n",
    "train_data = dataset.map(lambda data:tf.cast(data['image']\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    total_loss, total_recon, total_kl = 0, 0, 0\n",
    "    for x in train_data:\n",
    "        loss, recon, kl = train_step(x)\n",
    "        total_loss += loss * x.shape[0]\n",
    "        total_recon += recon\n",
    "        total_kl += kl\n",
    "        \n",
    "    if epoch % log_interval == 0:\n",
    "        print(f\"{epoch:3d} iteration: ELBO{total_loss / len(dataset):.2f}\",\n",
    "              f\"Recon: {total_recon / len(dataset):.2f}\",\n",
    "              f\"KL: {total_kl / len(dataset):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
